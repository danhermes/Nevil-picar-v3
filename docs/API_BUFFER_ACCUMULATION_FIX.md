# API Buffer Accumulation Issue - Critical Fix

**Date**: 2025-11-20
**Issue**: Two different responses to same prompt, STT repetitions back

## Problem Analysis

### Symptoms
- User speaks once
- TWO separate transcriptions arrive
- First transcription has massive repetitions (e.g., "I'd hate that" x9)
- Second transcription is completely different text
- AI responds to BOTH transcriptions separately

### Example from Logs
```
20:06:52 - VAD: Speech ended, commit 1856 samples
20:07:00 - Transcription 1: "I'd hate that. I'd hate that. I'd hate that..." (9x)
20:07:15 - VAD: Speech ended AGAIN, commit 3584 samples
20:07:16 - Transcription 2: "Kill Bill is a war not going anywhere..."
```

### Root Cause

**OpenAI Realtime API buffer was accumulating audio continuously**

We were clearing the LOCAL buffer but not the API's buffer:

1. **Continuous Streaming**: We send audio chunks continuously to the API
2. **API Buffer Accumulates**: OpenAI's server-side buffer keeps ALL audio
3. **VAD Detects Speech**: User speaks, VAD detects start
4. **User Pauses**: Natural pause in speech
5. **VAD Detects End**: Commits buffer with `input_audio_buffer.commit`
6. **API Commits EVERYTHING**: API commits all accumulated audio, not just the speech
7. **Repetitive Transcription**: Transcription contains repeated phrases from continuous stream
8. **User Continues**: User continues speaking after pause
9. **Second Commit**: Another commit with different accumulated audio
10. **Second Transcription**: Completely different text from continued speech

**The Core Issue**: We were only clearing our LOCAL buffer (Python side) but never clearing the API buffer (OpenAI server side), so it kept accumulating audio from the continuous stream.

## The Fix

**Clear API buffer at SPEECH START, not just after commit**

### Implementation (audio_capture_manager.py:686-694)

```python
if not self.vad_speech_active:
    # Speech started
    self.vad_speech_active = True
    self.vad_speech_start_time = time.time()
    self.logger.debug("VAD: Speech started")

    # ‚ö†Ô∏è CRITICAL: Clear API buffer at START of speech to prevent accumulation
    # This ensures only the CURRENT utterance is in the buffer when we commit
    if self.connection_manager:
        try:
            clear_event = {"type": "input_audio_buffer.clear"}
            self.connection_manager.send_sync(clear_event)
            self.logger.debug("üóëÔ∏è Cleared API audio buffer at speech start")
        except Exception as e:
            self.logger.error(f"Error clearing API buffer at speech start: {e}")
```

## Flow Comparison

### Before Fix (Accumulation)
```
[Continuous audio streaming to API buffer]
t=0s:  API buffer: [ambient noise chunks 1-100]
t=5s:  User: "Hey Nevil"
       API buffer: [ambient 1-100, "Hey" chunks 101-105]
t=6s:  VAD: Speech ended
       Commit API buffer
       API transcribes: [All 105 chunks] ‚Üí "noise noise noise Hey Hey Hey Nevil Nevil"
       ‚ùå REPETITION!

t=7s:  User: "how are you?"
       API buffer: [leftover chunks, "how are you" chunks 106-110]
t=8s:  VAD: Speech ended
       Commit API buffer
       API transcribes: [leftover + new] ‚Üí "are you you you how how"
       ‚ùå DIFFERENT TRANSCRIPTION!
```

### After Fix (Clean Isolation)
```
[Continuous audio streaming to API buffer]
t=0s:  API buffer: [ambient noise chunks 1-100]
t=5s:  User: "Hey Nevil"
       VAD: Speech START detected
       Clear API buffer ‚Üí API buffer: []
       API buffer: ["Hey" chunks 1-5, "Nevil" chunks 6-10]
t=6s:  VAD: Speech ended
       Commit API buffer
       API transcribes: [Only 10 chunks] ‚Üí "Hey Nevil"
       ‚úì CLEAN!

t=7s:  User: "how are you?"
       VAD: Speech START detected
       Clear API buffer ‚Üí API buffer: []
       API buffer: ["how are you" chunks 1-8]
t=8s:  VAD: Speech ended
       Commit API buffer
       API transcribes: [Only 8 chunks] ‚Üí "how are you?"
       ‚úì CLEAN SECOND TRANSCRIPTION!
```

## Why This Works

1. **Clean Start**: Each speech segment starts with empty API buffer
2. **Isolation**: Only the current utterance's audio is in buffer when committed
3. **No Accumulation**: Previous audio is cleared, preventing repetitions
4. **Natural Pauses**: User can pause mid-sentence and resume without issue

## Buffer Lifecycle

```
State: IDLE (no speech)
       ‚Üì
       Audio continuously streams to API
       API buffer accumulates: [ambient noise]
       ‚Üì
Event: VAD detects speech START
       ‚Üì
Action: input_audio_buffer.clear
       API buffer: [] (empty)
       ‚Üì
State: CAPTURING (speech active)
       ‚Üì
       Audio streams to API
       API buffer fills: [user speech chunks only]
       ‚Üì
Event: VAD detects speech END
       ‚Üì
Action: input_audio_buffer.commit
       API transcribes clean buffer
       ‚Üì
State: PROCESSING (waiting for transcription)
       ‚Üì
Event: Transcription arrives
       ‚Üì
State: IDLE (ready for next speech)
```

## Files Modified

1. **nevil_framework/realtime/audio_capture_manager.py**
   - Lines 686-694: Added API buffer clear on speech start
   - Sends `input_audio_buffer.clear` when VAD detects speech beginning

## Testing

Watch for the buffer clear messages:

```bash
sudo journalctl -u nevil -f | grep "üóëÔ∏è"
```

You should see:
```
[DEBUG] üóëÔ∏è Cleared API audio buffer at speech start
[DEBUG] üóëÔ∏è Cleared local audio buffer after commit
```

Two clears per utterance:
1. API buffer at START (prevents accumulation)
2. Local buffer after COMMIT (cleanup)

## Expected Behavior After Fix

### Single Utterance
```
User: "Hey Nevil, how are you?"
VAD: Speech start ‚Üí Clear API buffer
VAD: Speech end ‚Üí Commit API buffer
API: "Hey Nevil, how are you?" (clean, no repetition)
AI: 1 response
```

### Utterance with Natural Pause
```
User: "Hey Nevil ... [pause 2s] ... how are you?"
VAD: Speech start ‚Üí Clear API buffer
     Captures: "Hey Nevil"
VAD: Speech end ‚Üí Commit
     API: "Hey Nevil" (clean)

VAD: Speech start AGAIN ‚Üí Clear API buffer
     Captures: "how are you?"
VAD: Speech end ‚Üí Commit
     API: "how are you?" (clean, separate)

Result: 2 clean transcriptions, 2 AI responses (as intended for 2 utterances)
```

## Performance Impact

- **Minimal**: Clear operation is very fast (<1ms)
- **No data loss**: Only ambient noise discarded, speech fully captured
- **Better accuracy**: Cleaner audio = better transcriptions
- **No token waste**: No repeated phrases to process

## Related Fixes

This fix works together with:

1. **Queue Buildup Fix**: Prevents multiple responses to same speech
2. **Local Buffer Clear**: Cleanup after commit (line 764-766)
3. **Pause/Resume**: Clean commit without race conditions (line 748-786)

All three fixes combine to ensure:
- Clean audio isolation
- Single response per utterance
- No repetitions
- No queue buildup

## Troubleshooting

### If Repetitions Still Occur

1. **Check for clear messages in logs**:
   ```bash
   sudo journalctl -u nevil -n 100 | grep "Cleared API audio buffer"
   ```

2. **Verify timing**:
   - Clear should happen BEFORE any speech audio is captured
   - Clear should appear in logs at "Speech started"

3. **Check for errors**:
   ```bash
   sudo journalctl -u nevil -n 100 | grep "Error clearing API buffer"
   ```

### If Transcriptions Get Cut Off

If clearing too aggressively:
- Check VAD threshold (currently 0.08)
- Increase min_speech_duration if needed
- Adjust vad_silence_threshold (currently 10 frames)

## References

- OpenAI Realtime API Buffer Management: https://platform.openai.com/docs/guides/realtime
- VAD Implementation: nevil_framework/realtime/audio_capture_manager.py
- Buffer Lifecycle: Lines 680-800
