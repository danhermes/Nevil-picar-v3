# Speech Recognition Node v2.2 Message Configuration
# Realtime API Streaming STT with OpenAI WebSocket

node_name: "speech_recognition_realtime"
version: "2.2"
description: "Streaming speech-to-text using OpenAI Realtime API WebSocket with response.audio_transcript.delta events"

# Topics this node publishes to
publishes:
  - topic: "voice_command"
    message_type: "VoiceCommand"
    description: "Recognized voice commands from realtime streaming STT"
    frequency: "on_demand"
    schema:
      text:
        type: "string"
        required: true
        description: "Recognized text from speech"
        max_length: 500
      confidence:
        type: "float"
        required: true
        description: "Recognition confidence (0.0 to 1.0)"
        min: 0.0
        max: 1.0
      timestamp:
        type: "float"
        required: true
        description: "Unix timestamp when speech was recognized"
      language:
        type: "string"
        required: false
        description: "Language code"
        default: "en-US"
      duration:
        type: "float"
        required: false
        description: "Duration of speech in seconds"
        min: 0.0
      conversation_id:
        type: "string"
        required: false
        description: "Unique conversation ID for tracking"
      mode:
        type: "string"
        required: false
        description: "Recognition mode"
        default: "realtime_streaming"

  - topic: "listening_status"
    message_type: "ListeningStatus"
    description: "Whether the node is actively listening"
    frequency: "on_change"
    schema:
      listening:
        type: "boolean"
        required: true
        description: "True if actively listening for speech"
      reason:
        type: "string"
        required: false
        description: "Reason for status change"

# Topics this node subscribes to
subscribes:
  - topic: "system_mode"
    message_type: "SystemMode"
    callback: "on_system_mode_change"
    description: "System-wide mode changes"
    schema:
      mode:
        type: "string"
        required: true
        description: "Current system mode"
        allowed: ["listening", "speaking", "thinking", "idle", "error"]
      timestamp:
        type: "float"
        required: true
        description: "Unix timestamp of mode change"

  - topic: "speaking_status"
    message_type: "SpeakingStatus"
    callback: "on_speaking_status_change"
    description: "Speech synthesis status updates"
    schema:
      speaking:
        type: "boolean"
        required: true
        description: "True if speech synthesis is active"
      text:
        type: "string"
        required: false
        description: "Text being spoken (if speaking=true)"

  - topic: "navigation_status"
    message_type: "NavigationStatus"
    callback: "on_navigation_status_change"
    description: "Navigation execution status updates"
    schema:
      status:
        type: "string"
        required: true
        description: "Current navigation status"
        allowed: ["idle", "executing", "completed", "error"]
      current_action:
        type: "string"
        required: false
        description: "Currently executing action"
      timestamp:
        type: "float"
        required: true
        description: "Unix timestamp"

# Node configuration
configuration:
  # Realtime API settings
  realtime:
    model: "gpt-4o-realtime-preview-2024-10-01"
    url: "wss://api.openai.com/v1/realtime"
    max_reconnects: 5
    reconnect_delay: 1.0
    connection_timeout: 30.0

  # Audio capture settings (24kHz PCM16 for Realtime API)
  audio:
    sample_rate: 24000           # Realtime API requires 24kHz
    channel_count: 1             # Mono
    buffer_size: 4096            # PyAudio buffer
    chunk_size: 4800             # 200ms at 24kHz

    # Voice Activity Detection (VAD) - filters ambient noise
    vad_enabled: true
    vad_threshold: 0.08                # Energy threshold (0.0-1.0) - LOWERED for better sensitivity
    vad_min_speech_duration: 0.3       # Minimum speech duration in seconds - filters brief noise bursts
    speech_timeout_ms: 1500            # Silence duration before committing phrase (milliseconds)
    auto_flush_ms: 5000                # Max phrase length before auto-commit (milliseconds)

  # Recognition settings
  recognition:
    language: "en-US"
    confidence_threshold: 0.5
    transcript_timeout: 2.0      # Process transcript after 2s of silence

  # Performance settings
  performance:
    max_queue_size: 10
    processing_timeout: 5.0
    streaming_mode: true
